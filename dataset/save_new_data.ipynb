{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on  dress_sleeveless_7716FF7QWP\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'P:\\Documentos\\HDSP\\Fashion_garments_measurements\\dataset\\sewfactory'\n",
    "save_path = 'P:\\Documentos\\HDSP\\Fashion_garments_measurements\\dataset\\Paula_dataset'\n",
    "\n",
    "def get_70_70_images(name):\n",
    "    good_dresses = []\n",
    "    images = []\n",
    "    for folder_dress in os.listdir(dataset_path):\n",
    "        if folder_dress.startswith(name):\n",
    "                try:\n",
    "                    image = Image.open(os.path.join(dataset_path, folder_dress, 'static/static_0_30.png'))\n",
    "                    # resize to 20x20\n",
    "                    image = image.resize((70, 70))\n",
    "                    # if pixel is not white, make it black\n",
    "                    for i in range(image.size[0]):\n",
    "                        for j in range(image.size[1]):\n",
    "                            if image.getpixel((i, j)) != (255, 255, 255):\n",
    "                                image.putpixel((i, j), (0, 0, 0))\n",
    "                    image = image.convert('L')\n",
    "                    image_np = np.array(image)\n",
    "                    images.append(image_np)\n",
    "                    #image.save(os.path.join(save_path, folder_dress+'.png'))\n",
    "                    good_dresses.append(folder_dress)\n",
    "                except:\n",
    "                    print('error on ', folder_dress)\n",
    "                    continue\n",
    "\n",
    "    return images, good_dresses\n",
    "\n",
    "images, good_dresses = get_70_70_images('dress')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indice: 0 pares encontrados: 17\n",
      "indice: 100 pares encontrados: 206\n",
      "indice: 200 pares encontrados: 319\n",
      "indice: 300 pares encontrados: 461\n",
      "indice: 400 pares encontrados: 582\n",
      "indice: 500 pares encontrados: 697\n",
      "indice: 600 pares encontrados: 790\n",
      "indice: 700 pares encontrados: 886\n",
      "indice: 800 pares encontrados: 1040\n",
      "indice: 900 pares encontrados: 1121\n",
      "indice: 1000 pares encontrados: 1237\n",
      "indice: 1100 pares encontrados: 1335\n",
      "indice: 1200 pares encontrados: 1391\n",
      "indice: 1300 pares encontrados: 1431\n",
      "indice: 1400 pares encontrados: 1487\n",
      "indice: 1500 pares encontrados: 1526\n",
      "indice: 1600 pares encontrados: 1551\n",
      "indice: 1700 pares encontrados: 1597\n",
      "indice: 1800 pares encontrados: 1631\n",
      "indice: 1900 pares encontrados: 1656\n",
      "indice: 2000 pares encontrados: 1699\n",
      "indice: 2100 pares encontrados: 1724\n",
      "indice: 2200 pares encontrados: 1737\n",
      "indice: 2300 pares encontrados: 1750\n",
      "indice: 2400 pares encontrados: 1758\n",
      "indice: 2500 pares encontrados: 1760\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n",
      "482\n"
     ]
    }
   ],
   "source": [
    "def find_uniques(unique_images):\n",
    "    counter=0\n",
    "    threshold = 0.98\n",
    "    n = len(unique_images)\n",
    "    similar_pairs_unique = []\n",
    "    for i in range(n):\n",
    "        index_i = good_dresses.index(unique_images[i])\n",
    "        for j in range(i + 1, n):\n",
    "            index_j =  good_dresses.index(unique_images[j])\n",
    "            sim = ssim(images[index_i], images[index_j])\n",
    "            if sim > threshold:\n",
    "                #print(good_dresses[i], good_dresses[j], sim)\n",
    "                counter = counter + 1\n",
    "                similar_pairs_unique.append((unique_images[i], unique_images[j], sim))\n",
    "                \n",
    "        if i%100 == 0:\n",
    "            print(\"indice:\", i, \"pares encontrados:\", counter)\n",
    "\n",
    "    unique_images = []\n",
    "    for i in range(len(similar_pairs_unique)):\n",
    "        unique_images.append(similar_pairs_unique[i][0])\n",
    "\n",
    "    unique_images = np.unique(unique_images)\n",
    "    print(\"----------------------------\\n\"\n",
    "          \"----------------------------\\n\"\n",
    "          \"----------------------------\\n\")\n",
    "    print(len(unique_images))\n",
    "    return unique_images\n",
    "\n",
    "\n",
    "\n",
    "unique_images = good_dresses.copy()\n",
    "unique_images = find_uniques(unique_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indice: 0 pares encontrados: 14\n",
      "indice: 100 pares encontrados: 416\n",
      "indice: 200 pares encontrados: 834\n",
      "indice: 300 pares encontrados: 1002\n",
      "----------------------------\n",
      "----------------------------\n",
      "----------------------------\n",
      "\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "unique_images_v2 = find_uniques(unique_images_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_unique_images(unique_images): \n",
    "    save_path = 'P:\\Documentos\\HDSP\\Fashion_garments_measurements\\dataset\\Paula_dataset_unique'\n",
    "\n",
    "    for folder_dress in unique_images:\n",
    "        image = Image.open(os.path.join(dataset_path, folder_dress, 'static/static_0_30.png'))    \n",
    "        image = image.convert('L')\n",
    "        image.save(os.path.join(save_path, folder_dress+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_unique_images(unique_images_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de manga: \n",
      "\n",
      "    - Ancha\n",
      "\n",
      "    - Estrecha\n",
      "\n",
      "\n",
      "\n",
      "Largo de manga:\n",
      "\n",
      "    - Sisa\n",
      "\n",
      "    - Corta\n",
      "\n",
      "    - Al hombro\n",
      "\n",
      "  \n",
      "\n",
      "Cuello: \n",
      "\n",
      "    - En V\n",
      "\n",
      "    - Redondo\n",
      "\n",
      "\n",
      "\n",
      "Largo de falda: \n",
      "\n",
      "    - Larga \n",
      "\n",
      "    - Corta\n",
      "\n",
      "    - Midi\n",
      "\n",
      "\n",
      "\n",
      "Ancho de falda:\n",
      "\n",
      "    - Ancha\n",
      "\n",
      "    - Pegada\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('unique_atributes.txt', 'r') as file_unique:\n",
    "    for line in file_unique:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_coords(coordinates, size = 250):\n",
    "    for coord in coordinates:\n",
    "        coord[0] = int(-3.5*coord[0] + size)\n",
    "        coord[1] = int(-3.5*coord[1] + size)\n",
    "    return coordinates\n",
    "\n",
    "def distance_between_points(p1, p2):\n",
    "    return ((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)**0.5\n",
    "\n",
    "\n",
    "def save_coordinates(folder, savepath):\n",
    "\n",
    "    prueba_path = \"P:/Documentos/HDSP/Fashion_garments_measurements/dataset/sewfactory/\"+folder+\"/static/\"+folder+\"_specification.json\"\n",
    "\n",
    "    with open(prueba_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for dress_part in [\"top_front\", \"top_back\", \"skirt_front\", \"skirt_back\"]:\n",
    "\n",
    "        coordinates = data['pattern']['panels'][dress_part]['vertices']\n",
    "        coordinates = process_coords(coordinates)\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "\n",
    "        # new image with white background\n",
    "        img = Image.new('RGB', (500, 500), color = (255, 255, 255))\n",
    "\n",
    "        # draw the first two dots \n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.ellipse((coordinates[0][0]-2, coordinates[0][1]-2, coordinates[0][0]+2, coordinates[0][1]+2), fill=(0,0,0), outline=(0,0,0))\n",
    "        draw.ellipse((coordinates[1][0]-2, coordinates[1][1]-2, coordinates[1][0]+2, coordinates[1][1]+2), fill=(0,0,0), outline=(0,0,0))\n",
    "\n",
    "        Y = []\n",
    "\n",
    "        with open(savepath+'/'+dress_part+'_distances.txt', 'w') as file:\n",
    "            for i in range(len(coordinates)): \n",
    "                first_y = coordinates[0][1]\n",
    "            \n",
    "                if coordinates[i][1] == coordinates[(i+1)%len(coordinates)][1]:\n",
    "                    draw.line((coordinates[i][0], coordinates[i][1], coordinates[(i+1)%len(coordinates)][0], coordinates[(i+1)%len(coordinates)][1]), fill=(255,0,0), width=2)\n",
    "                    Y.append(coordinates[i][1])\n",
    "                else:\n",
    "                    draw.line((coordinates[i][0], coordinates[i][1], coordinates[(i+1)%len(coordinates)][0], coordinates[(i+1)%len(coordinates)][1]), fill=(0,0,0), width=2)\n",
    "                draw.text((coordinates[i][0], coordinates[i][1]), str(i), (0,0,0), font=font)\n",
    "\n",
    "                file.write(\"[\" + str(i) + \",\" + str((i+1)%len(coordinates))+\"]: \"\n",
    "                        +str(distance_between_points(coordinates[i], coordinates[(i+1)%len(coordinates)]))+'\\n')\n",
    "\n",
    "            draw.line((250, first_y, 250, Y[1]), fill=(0,255,0), width=2)\n",
    "            draw.text((250, first_y), str(len(coordinates)+1), (0,0,0), font=font)\n",
    "            draw.text((250, Y[1]), str(len(coordinates)+2), (0,0,0), font=font)\n",
    "            file.write(\"[\" + str(len(coordinates)+1) + \",\" + str(len(coordinates)+2)+ \"]: \"+str(distance_between_points([250, first_y], [250, Y[1]]))+'\\n')\n",
    "\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.text((0, 0), dress_part, (0,0,0), font=font)\n",
    "\n",
    "        img.save(os.path.join(savepath, dress_part+'_points_coordinates.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dress_sleeveless_00F3PNYG6L.png\n",
      "dress_sleeveless_013LZJLUQ0.png\n",
      "dress_sleeveless_02OIQPCOWU.png\n",
      "dress_sleeveless_04HEL5MHFC.png\n",
      "dress_sleeveless_0IHJZ81F9V.png\n",
      "dress_sleeveless_0NQV4UR4G0.png\n",
      "dress_sleeveless_0PW8HGG42W.png\n",
      "dress_sleeveless_0R0VSXFOXW.png\n",
      "dress_sleeveless_0Z54DUIP2N.png\n",
      "dress_sleeveless_1DD7UEQN0L.png\n",
      "dress_sleeveless_1E8PI9A2DX.png\n",
      "dress_sleeveless_1M10E9IVBQ.png\n",
      "dress_sleeveless_1UHTWRK2NI.png\n",
      "dress_sleeveless_3Z2PED6ZZX.png\n",
      "dress_sleeveless_4CB7HGSP32.png\n",
      "dress_sleeveless_4IB8MCTXX9.png\n",
      "dress_sleeveless_4JIINXQRT6.png\n",
      "dress_sleeveless_4U2QZ6FAMH.png\n",
      "dress_sleeveless_5CS1KB1QUB.png\n",
      "dress_sleeveless_5HY9KKTT6W.png\n",
      "dress_sleeveless_5SQV9BLKBD.png\n",
      "dress_sleeveless_65I912EJNB.png\n",
      "dress_sleeveless_6BIU6715BK.png\n",
      "dress_sleeveless_6D4RA1FJMJ.png\n",
      "dress_sleeveless_6IVSIA6XEN.png\n",
      "dress_sleeveless_6ZOSV66T3F.png\n",
      "dress_sleeveless_72XWDNTO99.png\n",
      "dress_sleeveless_76JKKFORV9.png\n",
      "dress_sleeveless_7BA0B946DP.png\n",
      "dress_sleeveless_7EWI19AX5S.png\n",
      "dress_sleeveless_9GADOV728A.png\n",
      "dress_sleeveless_9N5T83TV04.png\n",
      "dress_sleeveless_9SR70XTBUE.png\n",
      "dress_sleeveless_9T2F08450H.png\n",
      "dress_sleeveless_9WDFLUHTWC.png\n",
      "dress_sleeveless_APHWJR687S.png\n",
      "dress_sleeveless_AW4LQQ4BP8.png\n",
      "dress_sleeveless_B9UAGB42A0.png\n",
      "dress_sleeveless_CEHVIB72VD.png\n",
      "dress_sleeveless_DGZ8KF1G45.png\n",
      "dress_sleeveless_DMZ6IKKJ4C.png\n",
      "dress_sleeveless_E9YVV8DUC2.png\n",
      "dress_sleeveless_EFHH85SJID.png\n",
      "dress_sleeveless_EQBHV77EGO.png\n",
      "dress_sleeveless_EV3GRR7SG7.png\n",
      "dress_sleeveless_F7DB97HXPT.png\n",
      "dress_sleeveless_FS5SWLZHFS.png\n",
      "dress_sleeveless_FZ9M2LCLKB.png\n",
      "dress_sleeveless_HODDLCE9ZK.png\n",
      "dress_sleeveless_IV66CPBEL7.png\n",
      "dress_sleeveless_IX1SWAUE2N.png\n",
      "dress_sleeveless_JB1H2YZ99C.png\n",
      "dress_sleeveless_JVIOMD20X9.png\n",
      "dress_sleeveless_KV77WBU59K.png\n",
      "dress_sleeveless_L082QJ2Y9H.png\n",
      "dress_sleeveless_M4OO3GPX6M.png\n",
      "dress_sleeveless_N6EGMYT8S0.png\n",
      "dress_sleeveless_N772SLE67A.png\n",
      "dress_sleeveless_NGZE0EGOBR.png\n",
      "dress_sleeveless_OWVZKWQ7AO.png\n",
      "dress_sleeveless_PA2C9COYA2.png\n",
      "dress_sleeveless_PCUAR905UV.png\n",
      "dress_sleeveless_QKO30A4E0M.png\n",
      "dress_sleeveless_RE67XCIEVD.png\n"
     ]
    }
   ],
   "source": [
    "new_path = 'P:\\Documentos\\HDSP\\Fashion_garments_measurements\\dataset\\Paula_dataset_unique'\n",
    "import shutil\n",
    "\n",
    "dataset_path = 'P:\\Documentos\\HDSP\\Fashion_garments_measurements\\dataset\\sewfactory'\n",
    "save_path = 'P:\\Documentos\\HDSP\\Fashion_garments_measurements\\dataset\\Clean_dataset'\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(new_path):\n",
    "    if file.endswith('.png'):\n",
    "        print(file)\n",
    "        folder = file.split('.')[0]\n",
    "        txt_file = file.replace('.png', '_atributes.txt')\n",
    "        if not os.path.exists(os.path.join(save_path, folder)):\n",
    "            os.mkdir(os.path.join(save_path, folder))\n",
    "        # copiar txt de los atributos de la prenda\n",
    "        shutil.copy(os.path.join(new_path, txt_file), os.path.join(save_path, folder, txt_file))\n",
    "\n",
    "        # copiar imagenes de la prenda\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_0_30.png'), os.path.join(save_path, folder, folder+'_static_0_30.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_30_0.png'), os.path.join(save_path, folder, folder+'_static_30_0.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_60_0.png'), os.path.join(save_path, folder, folder+'_static_60_0.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_120_0.png'), os.path.join(save_path, folder, folder+'_static_120_0.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_150_0.png'), os.path.join(save_path, folder, folder+'_static_150_0.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_210_0.png'), os.path.join(save_path, folder, folder+'_static_210_0.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_240_0.png'), os.path.join(save_path, folder, folder+'_static_240_0.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_300_0.png'), os.path.join(save_path, folder, folder+'_static_300_0.png'))\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static/static_330_0.png'), os.path.join(save_path, folder, folder+'_static_330_0.png'))\n",
    "\n",
    "        shutil.copy(os.path.join(dataset_path, folder ,'static'+folder+'_'+folder+'_uv.png'), os.path.join(save_path, folder, folder+'_uv.png'))\n",
    "\n",
    "        save_coordinates(folder, save_path+'/'+folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de manga\n",
      "1. Ancha\n",
      "2. Estrecha\n",
      "['Tamaño de manga: Ancha\\n']\n",
      "Largo de manga\n",
      "1. Sisa\n",
      "2. Corta\n",
      "3. Al hombro\n",
      "['Tamaño de manga: Ancha\\n', 'Largo de manga: Corta\\n']\n",
      "Cuello\n",
      "1. En V\n",
      "2. Redondo\n",
      "['Tamaño de manga: Ancha\\n', 'Largo de manga: Corta\\n', 'Cuello: Redondo\\n']\n",
      "Largo de falda\n",
      "1. Larga\n",
      "2. Corta\n",
      "3. Midi\n",
      "['Tamaño de manga: Ancha\\n', 'Largo de manga: Corta\\n', 'Cuello: Redondo\\n', 'Largo de falda: Larga\\n']\n",
      "Ancho de falda\n",
      "1. Ancha\n",
      "2. Pegada\n",
      "['Tamaño de manga: Ancha\\n', 'Largo de manga: Corta\\n', 'Cuello: Redondo\\n', 'Largo de falda: Larga\\n', 'Ancho de falda: Pegada\\n']\n",
      "Tamaño de manga\n",
      "1. Ancha\n",
      "2. Estrecha\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, option \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(value):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moption\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m input_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSelect the option for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     28\u001b[0m lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue[input_value\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(lines)\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\Pauenv\\lib\\site-packages\\ipykernel\\kernelbase.py:1251\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\Pauenv\\lib\\site-packages\\ipykernel\\kernelbase.py:1295\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pau_env_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
